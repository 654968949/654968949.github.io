[{"title":"AICode闲谈","path":"/2025/12/26/AICode闲谈/","content":"代码写了也有五六年了，估计和大多程序员一样，空闲的时间里，总会去思考，市场上没人要我又去干嘛？如今AI编程工具层出不穷，大模型能力刷榜了一波又一波，似乎都指向了一个终点，程序员这个职业快没了。来探讨一下这两个问题看看。 有了AI编程工具，是不是程序员就要没了？ 首先这句话肯定是错的。现在出了这么多的工具。cursor，trae，qcode，gemini。他们使用者是谁？还不是程序员，那肯定程序员不会没了的。但是也会受到影响，原来一个需求，你要自己手搓一天，现在cursor写代码十分钟，你再改巴改巴一小时，估计就完成了，效率上肯定是大提升，既然没有那么多的工作量，那么程序小哥就不用招那么多了，虽然cursor使用也要付费，但是比起人工来说，cursor还是便宜的多的多了。这就变向缩小了招聘人数。如果AI工具普及了，那势必是会淘汰一批程序员，他们是这种人：不愿意使用AI工具编程，不善于使用AI辅助工具编程，没有编程的核心能力的。 为什么这么说？针对前两点，不愿意、不善于使用AI编程，很好理解了，等到大家都统一认知了。原来这个一天的工作量其实就是两个小时你+AI工具，你怎么应对？难道说因为你不使用工具就将就你，显然不可能，公司不会招这样的人浪费财力和时间。 针对最后一点。没有编程的核心能力。wait..?不是有AI工具帮你就行了吗？那AI写完的代码质量谁来保证？AI自己在review一遍保证自己吗？显然不行啊。所以我说的核心的能力，就是对代码的实现优雅性、整体模块划分、业务边缘划分、程序性能、安全考虑，这些方面还得你自己把关才行。因为AI编程的代码出线上的大问题，锅还是你自己背吧？不是AI来背吧？所以第一责任人还是自己。那你自己就得有这些核心能力，才能在这些编程工具中使用游刃有余，辨知真假。 我也给出一些主观的推论，未来的程序员，AI辅助的已是大势所趋，只等一个时间来推动，等国内厂家做好，价格打下来，到时候程序员们就真的是每个人的IDE都是TAB、TAB、TAB一直补全了。 所以无论如何请加入AI辅助编程吧。无论是你没钱，用免费的chat对话也好，自己充钱用AI编程工具也好，你得加入，不然真的会掉队。","tags":["随心"],"categories":["随心"]},{"title":"PolarDB浅介绍","path":"/2025/09/25/PolarDB浅介绍/","content":"一、对比RDS-MySQL有什么不同 对比维度 PolarDB RDS-MySQL 核心架构 云原生，计算，存储分离，一写多读 主从复制架构，计算存储耦合 扩展能力 计算和存储都可以轻松扩展 扩展性相对受限，垂直扩展（升配）为主，水平扩展较复杂 性能特点 高并发优化，大数据量场景优势明显，支持最多16个读节点 性能依赖单机或有限只读实例，高并发下易遇瓶颈 成本模式 由于其高性能特性，对于大型和高并发的应用场景，PolarDB可能更加经济高效。 对于中小型业务，或者业务峰值不是很高的场景，RDS MySQL可能是更加成本有效的选择 使用场景 高并发、大数据量、需弹性伸缩的互联网及企业核心应用（OLTPOLAP） 中小型项目、预算敏感、业务负载稳定且可预测的应用 OLTP：Online Transaction Processing 中文翻译：联机事务处理 或 在线事务处理 “联机”在这里指的是系统直接面向业务、进行实时交互处理。 代表数据库：MySQL, PostgreSQL, Oracle, SQL Server, PolarDB OLAP：Online Analytical Processing 中文翻译：联机分析处理 或 在线分析处理 代表数据库：Amazon Redshift, Google BigQuery, ClickHouse, Apache Doris 二、架构图2.1 PolarDB 2.2 RDS-MySQL","tags":["MySQL，PolarDB"],"categories":["数据库"]},{"title":"gateway在微服务中的作用及常见用法","path":"/2025/09/24/gateway在微服务中的作用及常见用法/","content":"一、网关在微服务中的作用 路由转发，将外部请求经由gateway路由转发至相应的微服务 熔断限流，入口都在gateway，自然可以对请求进行熔断限流处理 认证授权，同上理 处理请求的通用逻辑 Spring-Cloud体系常用的网关有gateway，zuul（已停止维护） 二、gateway在Spring-Cloud里面具体怎么使用？2.1 服务路由通常这个路由是写在YAMLProperties 文件中的，例如： server: port: 10010 # 网关服务端口spring: application: name: api-gateway # 服务名 cloud: nacos: # 配置 Nacos 注册中心地址 discovery: server-addr: localhost:8848 gateway: discovery: locator: enabled: true # 开启从服务发现中心自动创建路由的功能（可选） routes: - id: user-service # 路由唯一标识 uri: lb://userservice # 目标服务地址，lb:// 表示启用负载均衡 predicates: # 断言数组，条件必须全部满足 - Path=/user/** # 路径匹配 - After=2023-01-20T17:42:47.789-07:00[America/Denver] # 时间后匹配（可选） filters: - RewritePath=/user/(?path.*), /$\\path # 重写请求路径，例如将 /user/foo 变为 /foo - AddRequestHeader=X-Request-Gateway, Spring-Cloud-Gateway # 添加请求头 # 默认过滤器，对所有路由生效 default-filters: - AddResponseHeader=X-Response-Default-Filter, Default-Value 但是生产环境你不可能要改个什么东西，去重启gateway吧。所以通常是结合配置中心来动态刷新，以nacos为例，需要先配置bootstrap.yml文件 spring: application: name: your-gateway-service # 应用名，也是Nacos中Data ID的一部分 cloud: nacos: discovery: server-addr: localhost:8848 # Nacos服务器地址 config: server-addr: localhost:8848 file-extension: yaml # 配置文件的扩展名，支持yaml, properties等 group: DEFAULT_GROUP # 配置分组，默认为DEFAULT_GROUP # namespace: your-namespace-id # 命名空间ID，非必填，用于环境隔离 在 Nacos 中创建路由配置 登录 Nacos 控制台，在 配置管理 - 配置列表 中创建一个新的配置。 Data ID: 通常格式为 {spring.application.name}.{file-extension}，例如你的应用名是 your-gateway-service，文件扩展名是 yaml，那么 Data ID 就填 your-gateway-service.yaml。 Group: 与 bootstrap.yml 中配置的 group 一致，默认为 DEFAULT_GROUP。 配置内容: 将原本写在 application.yml 里的 spring.cloud.gateway.routes 部分移到这里。 spring: cloud: gateway: routes: - id: user-service-route uri: lb://user-service # 使用负载均衡形式 predicates: - Path=/user/** filters: - RewritePath=/user/(?segment.*), /$\\segment - id: product-service-route uri: lb://product-service predicates: - Path=/product/** 配置发布后，网关服务启动时会自动拉取该配置并加载路由规则。当你在 Nacos 上修改此配置并发布时，网关会自动感知并更新路由，无需重启。 2.2 全局链式过滤器GlobalFilterGlobalFilter是用于实现全局性的逻辑，如认证、日志、限流等。你需要通过实现 GlobalFilter 接口来自定义 @Component@Order(-1) // 定义过滤器执行顺序，数值越小优先级越高public class AuthGlobalFilter implements GlobalFilter @Override public MonoVoid filter(ServerWebExchange exchange, GatewayFilterChain chain) // 1. 获取请求参数等 // 2. 判断逻辑，例如检查token // 3. 放行 (chain.filter(exchange)) 或拦截返回未认证错误 return chain.filter(exchange);","tags":["gateway"],"categories":["Spring-Cloud"]},{"title":"mysql执行alter语句锁表了怎么办？","path":"/2025/08/25/MYSQL执行alter语句锁表了怎么办？/","content":"一、执行的ALTER语句ALTER TABLE order_info ADD COLUMN `flag` int(11) default 0 not null comment 0-不急 1--急; 假设这个表数量比较大，有一千万数据，同时你又有业务场景对它增删改查，肯定会锁表的。锁表了你们业务就会异常，肯定就会监控报警 二、解决锁表问题SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST WHERE DB = 你的数据库名 and INFO LIKE %你的表名%; 拿到id kill id 三、如何预防最好有专门的sql执行平台和维护人员，比如Yearning，可以防止这类问题发生。 如果没有这些条件，又必须要加字段，执行的时候加上onlineDDL关键字，在业务低峰执行 ALTER TABLE order_info algorithm = inplace, lock = none, ADD COLUMN `flag` int(11) default 0 not null comment 0-不急 1--急; lock none，表示在执行ALTER TABLE语句期间不对表进行锁定，允许其他会话对表进行读写操作。这种方式可以提高并发性，但可能会导致数据不一致的情况。 algorithm inplace，明确指示 MySQL 尝试在原地修改表结构。这意味着 MySQL 将尝试尽可能在不重新创建整个表的情况下应用修改 这样执行效率会高很多。而且不会锁表。","tags":["实战"],"categories":["MYSQL"]},{"title":"python合并相同格式的excel（带合并进度条）","path":"/2025/08/15/python合并相同格式的excel（带合并进度条）/","content":"import os as osimport pandas as pdfrom tqdm import tqdmdef run(): folder_path = /Users/woods/Downloads/订单明细报表20231221-20240120_1706771798179 # 获取文件夹中所有的 Excel 文件路径 excel_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(.xlsx)] # 创建一个空的 DataFrame 用于存储合并后的数据 merged_df = pd.DataFrame() # 遍历 Excel 文件并合并数据 for excel_file in tqdm(excel_files, desc=合并进度, dynamic_ncols=True): # 读取当前 Excel 文件 df = pd.read_excel(excel_file) # 合并到主 DataFrame merged_df = pd.concat([merged_df, df], ignore_index=True) # 获取总行数 total_rows = len(merged_df) # 使用 tqdm 显示合并进度 with tqdm(total=total_rows, desc=保存进度, dynamic_ncols=True) as pbar: # 将合并后的数据保存到新的 Excel 文件 chunk_size = 1000 # 指定每次保存的块大小 for i in range(0, total_rows, chunk_size): chunk_df = merged_df[i:i + chunk_size] chunk_df.to_excel(合并后的文件.xlsx, index=False, engine=xlsxwriter) pbar.update(len(chunk_df))if __name__ == __main__: run()","tags":["Python与Excel"],"categories":["Python工具"]},{"title":"clickhouse基础学习","path":"/2023/09/28/clickhouse基础学习/","content":"一、是什么ClickHouse是一个开源的列式数据库管理系统，专门设计用于处理大规模数据分析和OLAP（在线分析处理）工作负载。它最初由俄罗斯的Yandex公司开发，并于2016年发布为开源项目。 二、有什么特点 列式存储：ClickHouse以列式存储方式组织数据，这意味着相同列中的数据存储在一起，这种存储方式在分析查询和聚合操作中非常高效。 高性能：ClickHouse被设计成能够处理非常大的数据集，并能够快速执行复杂的分析查询。它通过使用多核CPU和高度优化的查询执行引擎来实现高性能。 支持SQL：ClickHouse支持SQL查询语言，这使得它易于使用和集成到现有的数据分析工具和应用程序中。 分布式架构：ClickHouse可以轻松扩展到多个节点，以处理大规模数据集。它支持数据分片、负载均衡和故障容忍，以确保高可用性和可伸缩性。 实时数据导入：ClickHouse支持实时数据导入，可以从各种数据源实时接收数据，这对于处理流式数据和实时分析非常有用。 开源：ClickHouse是开源的，可以免费使用和定制，因此它在许多组织中得到了广泛的应用。 三、常用的业务场景 数据仓库: ClickHouse可以用作企业数据仓库，用于存储和分析大规模的历史数据。它支持高性能的复杂查询和聚合操作，有助于发现数据中的趋势和洞察。 实时报告和仪表盘: ClickHouse可以用于构建实时报告和仪表盘，通过实时数据导入和快速查询执行，帮助业务决策者实时监控业务绩效。 广告分析: 在广告技术领域，ClickHouse可用于跟踪广告活动的效果，分析点击率、转化率和ROI等关键指标。 日志分析: ClickHouse非常适合处理大量日志数据，例如服务器日志、应用程序日志和网络流量日志。它能够快速执行日志分析查询，帮助识别问题和异常。 事件追踪: 许多应用程序需要追踪用户活动和事件。ClickHouse可以用于存储和分析这些事件数据，以提供洞察用户行为和趋势的见解。 时序数据分析: 时序数据（例如传感器数据、监控数据、时间序列数据库中的数据）的存储和分析是ClickHouse的另一个强大用途。它支持时间窗口查询和聚合，使其成为处理时序数据的理想选择。 数据湖分析: ClickHouse可以与数据湖架构集成，用于在数据湖中存储和分析大规模数据集。 在线广告投放: ClickHouse可以帮助广告技术公司实时调整广告投放策略，以提高广告的定位精度和效率。 金融分析: 金融领域需要处理大量的交易和市场数据。ClickHouse可以用于执行复杂的金融分析，例如风险评估、投资组合优化和市场趋势分析。 运营分析: 企业可以使用ClickHouse来分析运营数据，包括库存管理、供应链优化和客户关系管理。 总之，ClickHouse在需要大规模数据存储、高性能查询和实时数据分析的各种业务场景中都可以发挥作用。它的设计使其适用于处理大数据和复杂分析需求的情况。 四、为什么它可以查询的这么快？ 列式存储: 列式存储，减少IO操作和数据传输量。ClickHouse采用列式存储，这意味着它将相同列的数据存储在一起，而不是行式存储中将整行数据存储在一起。这种列式存储方式使得只需读取和解析实际需要的列数据，从而减少了IO操作和数据传输量。这对于数据分析查询非常高效，因为通常只需要一部分列数据来回答查询。 数据压缩: 压缩减少传输时间。ClickHouse使用高度优化的压缩算法，将数据在存储时压缩，这不仅减小了磁盘占用空间，还减少了数据传输时间。在查询时，ClickHouse能够在内存中快速解压数据，从而加快查询速度。 多核并行处理: 数据存在分布式多态服务器上，利用多台服务器的CPU并行查询。ClickHouse充分利用多核CPU和多线程技术，可以并行执行查询操作。这意味着可以同时处理多个查询片段，提高了查询性能。 合并操作: 按照查询条件只查询某些数据块的数据，扫描的数据范围会变小。ClickHouse使用合并操作来优化查询，避免不必要的数据移动。它将数据按块（block）存储，并在查询时尽可能使用整个块。这减少了不必要的数据复制和操作。 索引技术: ClickHouse支持索引，这可以加速某些查询，特别是在过滤条件上使用索引列时。索引使得数据的查找更加高效，从而加速了查询。 向量化执行: ClickHouse使用向量化查询执行，这意味着它可以在一次操作中处理多个数据点，而不是逐个处理。这种向量化执行方式减少了CPU指令的开销，提高了查询速度。 数据分区和负载均衡: ClickHouse支持数据分区和负载均衡，可以将数据分散存储在多个节点上，并在查询时将工作负载均衡分配到不同的节点上。这有助于水平扩展和提高查询性能。 五、clickhouse的底层数据存储数据在clickhouse以何种形式被存储要看使用的是什么表引擎。表引擎，决定了一张 数据表最终的性格，它拥有何种特性、数据以何种形式被存储以及如何被加载。 5.1 MergeTree家族（合并树）之所以说是合并树家族，是因为MergeTree衍生了好几个与之类似的引擎。 MergeTree 最基础的版本,支持数据分区,后台自动合并。 ReplacingMergeTree: 支持替换旧数据的MergeTree。在同一个分区内，clickhouse在后台合并数据的时候会删除重复数据，注意这里是同一个分区内的去重效果。 SummingMergeTree: 支持把多行数据合并求和的MergeTree。在合并分区的时候，将同一分组下的多行数据提前汇总合并成一行，这样减少了数据行，又降低了后续汇总查询的开销。 AggregatingMergeTree: 支持聚合的MergeTree。将需要聚合的数据预先计算出来，并将结果保存起来，在后续进行聚合查询的时候直接使用结果数据。 CollapsingMergeTree: 支持数据折叠（意思就是以增代删）的MergeTree。它通过定义一个sign标志位字段，记录数据行的状态，如果sign标记为1，则表示这是一行有效的数据，如果是-1，则表示这行数据需要被删除。CollapsingMergeTree合并数据时，同一分区，sign为1和-1的数据会被抵消删除。犹如折叠一般。这个引擎还有个使用条件，就是对于写入数据的顺序有严格的要求，如果先写入sign-1的数据，在写入sign1的数据，则不能够折叠。所以如果你写入数据是用的多线程写入，大概率有问题。 VersionedCollapsingMergeTree:结合版本控制的CollapsingMergeTree。这个就是为了解决上面说的写入顺序的问题。加了个版本号。数据会自动按照orderby version，这样就有确定的顺序。 ……等等 5.2 Memory（内存）5.3 文件5.4 第三方自定义","tags":["clickhouse"],"categories":["clickhouse"]},{"title":"easyPoi自定义代码导出报表","path":"/2023/08/18/easyPoi自定义代码导出报表/","content":"一、问题 这种，表头是两行构成一行是一个单元格，一行是两个单元格，并且单元格是不确定的，会动态增加的，有得力，有京东，小米，华为…….。想要图快，使用easyPoi的模版导出，好像是不太现实，只好用写代码的方式来操作。但是也不是完全凭自己的方式来。用easyPoi带的一些方法来操作。 二、写代码public static void testPoi2() try //装很多表头的集合 ListExcelExportEntity colList = new ArrayList(); //一个表头 ExcelExportEntity colEntity = new ExcelExportEntity(商品名称, title); //对比上面的那个图片来说，就是[供应商0]可以对应后面的三个[得力.市场价] 供应商0合并为一个单元格的意思 colEntity.setNeedMerge(true); colList.add(colEntity); colEntity = new ExcelExportEntity(供应商, supplier); colEntity.setNeedMerge(true); colList.add(colEntity); //一个单元格组 ExcelExportEntity deliColGroup = new ExcelExportEntity(得力, deli); ListExcelExportEntity deliColList = new ArrayList(); //得力下面挂两个小单元格 deliColList.add(new ExcelExportEntity(市场价, orgPrice)); deliColList.add(new ExcelExportEntity(专区价, salePrice)); deliColGroup.setList(deliColList); //放入表头集合 colList.add(deliColGroup); ExcelExportEntity jdColGroup = new ExcelExportEntity(京东, jd); ListExcelExportEntity jdColList = new ArrayListExcelExportEntity(); jdColList.add(new ExcelExportEntity(市场价, orgPrice)); jdColList.add(new ExcelExportEntity(专区价, salePrice)); jdColGroup.setList(jdColList); colList.add(jdColGroup); //装很多行数据的集合 一个MAP代表一行数据 ListMapString, Object list = new ArrayList(); for (int i = 0; i 10; i++) //一行数据 MapString, Object valMap = new HashMap(); valMap.put(title, 名称. + i); valMap.put(supplier, 供应商. + i); ListMapString, Object deliDetailList = new ArrayList(); for (int j = 0; j 3; j++) //一行 MapString, Object deliValMap = new HashMap(); deliValMap.put(orgPrice, 得力.市场价.); deliValMap.put(salePrice, 得力.专区价.); deliDetailList.add(deliValMap); //deli字段是一个单元格组合 valMap.put(deli, deliDetailList); ListMapString, Object jdDetailList = new ArrayList(); for (int j = 0; j 2; j++) MapString, Object jdValMap = new HashMap(); jdValMap.put(orgPrice, 京东.市场价.); jdValMap.put(salePrice, 京东.专区价.); jdDetailList.add(jdValMap); valMap.put(jd, jdDetailList); list.add(valMap); System.out.println(JSON.toJSONString(list)); ExportParams entity = new ExportParams(价格分析表, 数据); Workbook workbook = ExcelExportUtil.exportExcel(entity, colList, list); FileOutputStream fos = new FileOutputStream(/Users/woods/testpoi/价格分析表.xls); workbook.write(fos); fos.close(); catch (IOException e) e.printStackTrace(); 三、总结如上面代码所示，导出来的数据就和本文的那张图片一样，表头比较复杂的情况下，可以考虑使用这种方式导出","tags":["easyPoi"],"categories":["报表开发"]},{"title":"OpenFeign(9.5.0)性能优化尝试","path":"/2023/04/20/OpenFeign(9.5.0)性能优化尝试 /","content":"一、为什么需要优化？​ 微服务之间的RPC调用使用的OpenFeign组件，并且完全使用的默认设置，默认的设置包括： 1.1 HTTP客户端默认使用的HttpURLConnection，这是java自带的发送http请求的API，优点就是java自带的，调用的时候方便，缺点就是性能和安全方面 缺点 HttpURLConnection每次请求都会打开一个新的TCP连接，不复用TCP连接，这会导致在高并发场景下HTTP请求和响应的速度变慢 比较繁琐，需要手动进行请求的创建、连接、读取和关闭等操作； 线程安全性不如其他并发包，需要在多线程环境中进行适当的同步； 对响应数据的读取需要手动进行，需要调用IO流API进行读取。 现状目前使用的默认的HttpURLConnection 1.2 重试策略默认的重试策略 @Configurationpublic class FeignClientsConfiguration @Bean@ConditionalOnMissingBean\tpublic Retryer feignRetryer() return Retryer.NEVER_RETRY; 默认是永不重试，请求五秒超时后就抛异常结束 现状目前重试策略由第三方组件Guava手动实现重试，需要重试的接口自己实现重试机制。 1.3 日志打印策略public enum Level /** * No logging. */ NONE, /** * Log only the request method and URL and the response status code and execution time. */ BASIC, /** * Log the basic information along with request and response headers. */ HEADERS, /** * Log the headers, body, and metadata for both requests and responses. */ FULL 默认是NONE，不打印feign的请求响应日志 现状目前是默认的不打印feign的请求响应日志 1.4 编码解码策略@Bean@ConditionalOnMissingBeanpublic Decoder feignDecoder() return new ResponseEntityDecoder(new SpringDecoder(this.messageConverters));@Bean@ConditionalOnMissingBeanpublic Encoder feignEncoder() return new SpringEncoder(this.messageConverters); 默认使用是是SpringEncoder和SpringDecoder（它们共同作用于HTTP消息转换，其中SpringEncoder用于将Java对象转换为请求的HTTP消息体，SpringDecoder将响应的HTTP消息体转换为相应的Java对象） 以下是一个HTTP消息体的例子： POST /api/books HTTP/1.1Host: example.comContent-Type: application/json title: The Hitchhikers Guide to the Galaxy, author: Douglas Adams, year: 1979, publisher: Pan Books, isbn: 978-0330508537, language: English, format: paperback, pages: 224 现状目前是默认配置 二、目前可以优化那些方面目前我们主要想提升的是feign接口的性能，因为平时总会有一些feign接口超时，但是具体去排查，并不是数据库响应的问题，所以我们需要对feign本身的请求性能进行优化。 重试策略我们可以不做改动，需要重试的地方就自己实现。 feign请求响应日志打印这一块，我们也为了性能使用默认不打印（好像也没有这种需要）。 编码解码策略也可以使用默认，性能提升不在这。 所以优化重点放在了Feign的HTTP客户端。 三、Feign-HTTP客户端替换3.1 我们该如何配置不做特殊配置的话，在pom文件里面加上http客户端，SpringBoot应用就可以识别并使用到。但是需要做特殊配置的话就不行。 dependency groupIdio.github.openfeign/groupId artifactIdfeign-httpclient/artifactId/dependency 9.5.0版本的OpenFeign是不支持在yaml文件或者properties文件中配置的。在高版本的OpenFeign可以直接在ymal或者properties配置 ### Feign 配置feign: httpclient: # 开启 Http Client enabled: true # 最大连接数，默认：200 max-connections: 200 # 最大路由，默认：50 max-connections-per-route: 50 # 连接超时，默认：2000/毫秒 connection-timeout: 2000 # 生存时间，默认：900L time-to-live: 900 # 响应超时的时间单位，默认：TimeUnit.SECONDS# timeToLiveUnit: SECONDS### Feign 配置feign: httpclient: # 是否开启 Http Client enabled: false# # 最大连接数，默认：200# max-connections: 200# # 最大路由，默认：50# max-connections-per-route: 50# # 连接超时，默认：2000/毫秒# connection-timeout: 2000# # 生存时间，默认：900L# time-to-live: 900# # 响应超时的时间单位，默认：TimeUnit.SECONDS## timeToLiveUnit: SECONDS okhttp: enabled: true 那么在9.5.0该如何配置我们的最大连接数、连接超时时间等参数呢？ 肯定只能自己写配置文件来处理了 @Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignConfig @Bean public OkHttpClient okHttpClient() OkHttpClient.Builder clientBuilder = new OkHttpClient.Builder(); clientBuilder.readTimeout(10, TimeUnit.SECONDS) .writeTimeout(10, TimeUnit.SECONDS) .connectTimeout(5, TimeUnit.SECONDS) .retryOnConnectionFailure(true) .connectionPool(new ConnectionPool(255, 5, TimeUnit.MINUTES)); //.addInterceptor(okHttpInterceptor); return clientBuilder.build(); 发起一个Http请求，可以看到我们的配置是生效的 3.2 Feign(9.5.0)自动配置源码@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignAutoConfiguration @Configuration\t@ConditionalOnClass(OkHttpClient.class)\t@ConditionalOnMissingClass(com.netflix.loadbalancer.ILoadBalancer)\t@ConditionalOnProperty(value = feign.okhttp.enabled, matchIfMissing = true)\tprotected static class OkHttpFeignConfiguration @Autowired(required = false) private okhttp3.OkHttpClient okHttpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient() if (this.okHttpClient != null) return new OkHttpClient(this.okHttpClient); return new OkHttpClient(); //OkHttpClient是Client的实现类public final class OkHttpClient implements Client 当Springboot应用启动的时候，检测到类路径中有Feign类，并且没有com.netflix.loadbalancer.ILoadBalancer类时，才会加载这个配置，通俗讲，就是如果用到了Spring-Cloud的Ribbon负载均衡组件，FeignAutoConfiguration就不会加载OkHttpFeignConfiguration。 那什么时候初始化Feign的Client呢？ @ConditionalOnClass( ILoadBalancer.class, Feign.class )@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)//Order is important here, last should be the default, first should be optional// see https://github.com/spring-cloud/spring-cloud-netflix/issues/2086#issuecomment-316281653@Import( HttpClientFeignLoadBalancedConfiguration.class, OkHttpFeignLoadBalancedConfiguration.class, DefaultFeignLoadBalancedConfiguration.class )public class FeignRibbonClientAutoConfiguration @Configuration@ConditionalOnClass(OkHttpClient.class)@ConditionalOnProperty(value = feign.okhttp.enabled, matchIfMissing = true)class OkHttpFeignLoadBalancedConfiguration @Autowired(required = false)\tprivate okhttp3.OkHttpClient okHttpClient;\t@Bean\t@ConditionalOnMissingBean(Client.class)\tpublic Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) OkHttpClient delegate; if (this.okHttpClient != null) delegate = new OkHttpClient(this.okHttpClient); else delegate = new OkHttpClient(); return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); OK，我们看到在FeignRibbonClientAutoConfiguration类里面，主动使用@Import导入了OkHttpFeignLoadBalancedConfiguration配置类，配置类里面加载了OkHttpClient并委托给LoadBalancerFeignClient，供之后Feign的http调用时使用。 四、OkHttpClient参数的制定@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignConfig @Bean public OkHttpClient okHttpClient() OkHttpClient.Builder clientBuilder = new OkHttpClient.Builder(); clientBuilder.readTimeout(10, TimeUnit.SECONDS) .writeTimeout(10, TimeUnit.SECONDS) .connectTimeout(5, TimeUnit.SECONDS) .retryOnConnectionFailure(true) .connectionPool(new ConnectionPool(255, 5, TimeUnit.MINUTES)); //.addInterceptor(okHttpInterceptor); return clientBuilder.build(); 4.1 maxIdleConnectionsmaxIdleConnections 连接池大小，指单个okhttpclient实例所有连接的连接池。 如果设置的过大？将 maxIdleConnections 设置得过大可能会占用过多的系统资源，导致系统性能下降。因为连接池中的每个空闲连接都需要占据一定的内存，如果连接池中的连接数量过多，就会占用过多的内存资源。此外，连接池中的连接也会占用操作系统资源，例如文件句柄、线程等。 另外，将 maxIdleConnections 设置得过大也可能会影响网络请求的响应速度。因为连接池中的连接数量越多，每个连接就会得到更少的使用机会，导致连接空闲时间变长，从而增加网络请求的响应时间。 因此，应该根据应用的实际情况合理设置 maxIdleConnections 的值，以平衡资源利用和网络请求响应速度。 如果设置的过小？将 maxIdleConnections 设置得过小可能会导致连接池中的连接不足，从而影响网络请求的响应速度。因为当连接数不足时，新的请求需要等待现有的连接释放，才能够得到响应。如果请求量很大，等待连接释放的时间就会变长，从而导致网络请求的响应时间变长。 此外，将 maxIdleConnections 设置得过小也可能会导致连接频繁地被创建和关闭，从而降低连接的重用率，从而增加了系统负担和网络请求的响应时间。 因此，应该根据应用的实际情况合理设置 maxIdleConnections 的值，以确保连接池中的连接数量能够满足并发请求的需求，同时避免连接数量过多导致资源浪费。 到底设置多少合适？确定最优值需要考虑以下几个因素: 并发请求的数量。如果同时有很多请求，那么连接池中就需要有足够多的空闲连接，以便快速响应请求。 服务器的响应速度。如果服务器响应速度很快，那么连接池中的连接就会很快被释放，可以减少连接池中的空闲连接数。 应用的网络环境。如果网络延迟较高，那么连接池中的连接可能需要等待很长时间才能收到响应，因此需要更多的空闲连接。 一般来说，可以根据应用的实际情况进行调整。可以尝试不同的值，观察连接池中的空闲连接数和请求的响应时间，选择一个能够平衡资源利用和响应速度的值作为最终的配置。","tags":["Feign"],"categories":["SpringCloud"]},{"title":"CompletableFuture的使用","path":"/2022/09/02/CompletableFuture的使用/","content":"什么作用？引入CompletableFuture，对业务流程进行编排，降低依赖之间的阻塞。充分利用我们的CPU资源，不让我们的CPU资源大量浪费在阻塞等待上。 几种使用场景根据CompletableFuture依赖数量，可以分为以下几类：零依赖、一元依赖、二元依赖和多元依赖。 以下的CompletableFuture都以CF简称。 一、零依赖 这里的零依赖指的发起异步不需要依赖其他异步任务的结果。所以直接使用CompletableFuture发起一个异步调用即可。 ExecutorService executor = Executors.newFixedThreadPool(5);//1、使用runAsync或supplyAsync发起异步调用CompletableFutureString cf1 = CompletableFuture.supplyAsync(() - return result1;, executor); 二、一元依赖 这种情况就是一个CF的调用依赖于另外一个CF的完成或者完成结果。 可以通过CF里面的thenApply、thenAccept、thenCompose等方法来实现 ExecutorService executor = Executors.newFixedThreadPool(5); CompletableFutureString cf1 = CompletableFuture.supplyAsync(() - System.out.println(执行step 1); try Thread.sleep(2000); catch (InterruptedException e) e.printStackTrace(); return step1 result; , executor); CompletableFutureString cf2 = CompletableFuture.supplyAsync(() - System.out.println(执行step 2); try Thread.sleep(2000); catch (InterruptedException e) e.printStackTrace(); return step2 result; );CompletableFutureString stringCompletableFuture = cf1.thenApply(result - System.out.println(result); return 123123; ); String join = stringCompletableFuture.join(); System.out.println(join);##结果//执行step 1//执行step 2//step1 result//123123 三、二元依赖 这种情况就是指的依赖了两个CF的结果。 //方法体内的程序执行依赖cf1和cf2都执行完，并且把cf1和cf2的结果可以拿到cf1.thenCombine(cf2, (result1, result2) - System.out.println(result1 + , + result2); System.out.println(执行step 3); return step3 result; ).thenAccept(System.out::println); 四、多元依赖 这种情况就是依赖了多个CF的完成或者CF的结果 CompletableFutureVoid cf6 = CompletableFuture.allOf(cf3, cf4, cf5);CompletableFutureString result = cf6.thenApply(v - //这里的join并不会阻塞，因为传给thenApply的函数是在CF3、CF4、CF5全部完成时，才会执行 。 result3 = cf3.join(); result4 = cf4.join(); result5 = cf5.join(); //根据result3、result4、result5组装最终result; return result;);","tags":["高并发"],"categories":["异步编程"]},{"title":"学习Java反射类","path":"/2022/06/21/Java反射类/","content":"一、基本定义通常情况下编写代码都是固定的，无论运行多少次执行的结果也是固定的，在某些特殊场合中编写 代码时不确定要创建什么类型的对象，也不确定要调用什么样的方法，这些都希望通过运行时传递的参数来决定，该机制叫做动态编程技术，也就是反射机制。 通俗来说，反射机制就是用于动态创建对象并且动态调用方法的机制。 目前主流的框架底层都是采用反射机制实现的。 如: Person p new Person(); - 表示声明Person类型的引用指向Person类型的对象 p.show(); - 表示调用Person类中的成员方法show 二、Class类基本概念java.lang.Class类的实例可以用于描述Java应用程序中的类和接口，也就是一种数据类型。 该类没有公共构造方法，该类的实例由Java虚拟机和类加载器自动构造完成，本质上就是加载到内 存中的运行时类。 获取Class对象的方法（重点） 使用数据类型.class的方式可以获取对应类型的Class对象(掌握)。 使用Class.forName()的方式来获取参数指定类型的Class对象(掌握)。 使用引用对象.getClass()的方式可以获取对应类型的Class对象。 使用包装类.TYPE的方式可以获取对应基本数据类型的Class对象。 使用类加载器ClassLoader的方式获取指定类型的Class对象。 常用的方法 方法声明 功能介绍 static Class? forName(String className) 用于获取参数指定类型对应的Class对象并返回 T newInstance() 用于创建该Class对象所表示类的新实例 Class类的常用方法 方法声明 功能介绍 Constructor getConstructor(Class?… parameterTypes) 用于获取此Class对象所表示类型中参数指定的 parameterTypes) Constructor?[] getConstructors() 用于获取此Class对象所表示类型中所有的公共 构造方法（重要） Constructor类java.lang.reflect.Constructor类主要用于描述获取到的构造方法信息 Constructor类的常用方法 方法声明 功能介绍 T newInstance(Object… initargs) 使用此Constructor对象描述的构造方法来构造Class对象代表类 型的新实例 int getModifiers() 获取方法的访问修饰符 String getName() 获取方法的名称 Class?[] getParameterTypes() 获取方法所有参数的类型 三、Field类基本概念java.lang.reflect.Field类主要用于描述获取到的单个成员变量信息。 Class类的常用方法 方法声明 功能介绍 Field getDeclaredField(String name) 用于获取此Class对象所表示类中参数指定的单个成员变量信息 Field[] getDeclaredFields() 用于获取此Class对象所表示类中所有成员变量信息 getField和getDeclaredField的区别getField 只能获取public的，包括从父类继承来的字段。getDeclaredField 可以获取本类所有的字段，包括private的，但是不能获取继承来的字段。 (注： 这里只能获取到private的字段，但并不能访问该private字段的值,除非加上setAccessible(true)) Field类的常用方法 方法声明 功能介绍 Object get(Object obj) 获取参数对象obj中此Field对象所表示成员变量的数值**（重要）** void set(Object obj, Object value) 将参数对象obj中此Field对象表示成员变量的数值修改为参数, value的数值 void setAccessible(boolean flag) 当实参传递true时，则反射对象在使用时应该取消 Java 语言访 问检查 int getModifiers() 获取成员变量的访问修饰符 Class? getType() 获取成员变量的数据类型 String getName() 获取成员变量的名称 四、Method类基本概念java.lang.reflect.Method类主要用于描述获取到的单个成员方法信息。 Class类的常用方法 方法声明 功能介绍 Method getMethod(String name, Class?… parameterTypes) 用于获取该Class对象表示类中名字为name参数为 parameterTypes的指定公共成员方法 Method[] getMethods() 用于获取该Class对象表示类中所有公共成员方法 Method类的常用方法 方法声明 功能介绍 Object invoke(Object obj, Object… args) 使用对象obj来调用此Method对象所表示的成员方法，实 参传递args int getModifiers() 获取方法的访问修饰符 Class? getReturnType() 获取方法的返回值类型 String getName() 获取方法的名称 Class?[] getParameterTypes() 获取方法所有参数的类型 Class?[] getExceptionTypes() 获取方法的异常信息 获取其它结构信息 方法声明 功能介绍 Package getPackage() 获取所在的包信息 Class? super T getSuperclass() 获取继承的父类信息 Class?[] getInterfaces() 获取实现的所有接口 Annotation[] getAnnotations() 获取注解信息 Type[] getGenericInterfaces() 获取泛型信息","tags":["反射"],"categories":["Java基础知识"]},{"title":"SpringBoot的四种鉴权方式","path":"/2022/06/21/SpringBoot的四种鉴权方式/","content":"一、传统AOP切面类@Aspect public class WhitelistAspect @Before(value = whitelistPointcut() @annotation(whitelist)) public void checkAppkeyWhitelist(JoinPoint joinPoint, Whitelist whitelist) checkWhitelist(); // 可使用 joinPoint.getArgs() 获取Controller方法的参数 // 可以使用 whitelist 变量获取注解参数 @Pointcut(@annotation(com.zhenbianshu.Whitelist)) public void whitelistPointCut() 添加了切面类之后，在controller的方法上加@Whitelist注解实现功能。 二、InterceptorSpring 的 拦截器(Interceptor) 实现这个功能也非常合适。顾名思义，拦截器用于在 Controller 内 Action 被执行前通过一些参数判断是否要执行此方法，要实现一个拦截器，可以实现 Spring 的 HandlerInterceptor 接口。 实现步骤如下： 定义拦截器类 AppkeyInterceptor 类并实现 HandlerInterceptor 接口。 实现其 preHandle() 方法； 在 preHandle 方法内通过注解和参数判断是否需要拦截请求，拦截请求时接口返回 false； 在自定义的 WebMvcConfigurerAdapter 类内注册此拦截器； AppkeyInterceptor 类如下： @Component public class WhitelistInterceptor implements HandlerInterceptor @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception Whitelist whitelist = ((HandlerMethod) handler).getMethodAnnotation(Whitelist.class); // whitelist.values(); 通过 request 获取请求参数，通过 whitelist 变量获取注解参数 return true; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception // 方法在Controller方法执行结束后执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception // 在view视图渲染完成后执行 扩展要启用 拦截器还要显式配置它启用，这里我们使用 WebMvcConfigurerAdapter 对它进行配置。需要注意，继承它的的 MvcConfiguration 需要在 ComponentScan 路径下。 @Configuration public class MvcConfiguration extends WebMvcConfigurerAdapter @Override public void addInterceptors(InterceptorRegistry registry) registry.addInterceptor(new WhitelistInterceptor()).addPathPatterns(/*).order(1); // 这里可以配置拦截器启用的 path 的顺序，在有多个拦截器存在时，任一拦截器返回 false 都会使后续的请求方法不再执行 三、ArgumentResolver参数解析器是 Spring 提供的用于解析自定义参数的工具，我们常用的 @RequestParam 注解就有它的影子，使用它，我们可以将参数在进入Controller Action之前就组合成我们想要的样子。 Spring 会维护一个 ResolverList， 在请求到达时，Spring 发现有自定义类型参数（非基本类型）， 会依次尝试这些 Resolver，直到有一个 Resolver 能解析需要的参数。要实现一个参数解析器，需要实现 HandlerMethodArgumentResolver 接口。 实现 定义自定义参数类型 AuthParam，类内有 appkey 相关字段； 定义 AuthParamResolver 并实现 HandlerMethodArgumentResolver 接口； 实现 supportsParameter() 接口方法将 AuthParam 与 AuthParamResolver 适配起来； 实现 resolveArgument() 接口方法解析 reqest 对象生成 AuthParam 对象，并在此校验 AuthParam ，确认 appkey 是否在白名单内； 在 Controller Action 方法上签名内添加 AuthParam 参数以启用此 Resolver; @Component public class AuthParamResolver implements HandlerMethodArgumentResolver @Override public boolean supportsParameter(MethodParameter parameter) return parameter.getParameterType().equals(AuthParam.class); @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception Whitelist whitelist = parameter.getMethodAnnotation(Whitelist.class); // 通过 webRequest 和 whitelist 校验白名单 return new AuthParam(); 扩展当然，使用参数解析器也需要单独配置，我们同样在 WebMvcConfigurerAdapter内配置： 四、FilterFilter 并不是 Spring 提供的，它是在 Servlet 规范中定义的，是 Servlet 容器支持的。被 Filter 过滤的请求，不会派发到 Spring 容器中。它的实现也比较简单，实现 javax.servlet.Filter接口即可。 由于不在 Spring 容器中，Filter 获取不到 Spring 容器的资源，只能使用原生 Java 的 ServletRequest 和 ServletResponse 来获取请求参数。另外，在一个 Filter 中要显示调用 FilterChain 的 doFilter 方法，不然认为请求被拦截。实现类似： public class WhitelistFilter implements javax.servlet.Filter @Override public void init(FilterConfig filterConfig) throws ServletException // 初始化后被调用一次 @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException // 判断是否需要拦截 chain.doFilter(request, response); // 请求通过要显示调用 @Override public void destroy() // 被销毁时调用一次 扩展Filter 也需要显示配置： @Configuration public class FilterConfiguration @Bean public FilterRegistrationBean someFilterRegistration() FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new WhitelistFilter()); registration.addUrlPatterns(/*); registration.setName(whitelistFilter); registration.setOrder(1); // 设置过滤器被调用的顺序 return registration; 小结四种实现方式都有其适合的场 景，那么它们之间的调用顺序如何呢？Filter 是 Servlet 实现的，自然是最先被调用，后续被调用的是 Interceptor 被拦截了自然不需要后续再进行处理，然后是 参数解析器，最后才是切面的切点。","tags":["SpringBoot"],"categories":["SpringBoot"]},{"title":"docker搭建canal-server和canal-admin","path":"/2022/06/21/docker搭建canal-server和canal-admin/","content":"一、搭建有binlog功能的mysql1.1 先建两文件夹我是使用docker来搭建，在服务器上建这么两个目录，用来挂载docker里面的mysql的配置文件，和mysql的数据存储, 后面docker run要用 /etc/mysql ##挂载mysql的配置文件/opt/mysql ##挂载mysql的数据存储 1.2 拉取docker 镜像docker pull mysql:5.7 1.3 运行镜像docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=www123456 -v /etc/mysql:/etc/mysql -v /opt/mysql:/var/lib/mysql -v /etc/localtime:/etc/localtime mysql:5.7 1.4 查看挂载情况查看挂载情况，里面可以看到详细的挂载情况，可以看到我们的两个目录是被正确挂载了 docker inspect 容器名或者id 1.5 编辑mysql的配置文件直接在服务器上编辑mysql的配置文件（和docker容器里面的文件相互挂载了），里面有可能是空的，直接往里面加就行了 vim /etc/mysql/mysql.conf.d/mysqld.cnf[mysqld]log-bin=mysql-binbinlog-format=ROWserver_id=1 1.6 重启mysqldocker restart 容器名或者id 1.7 查看数据库的binlog是否开启用mysql工具查看数据库的binlog是否开启 show variables like %log_bin%; 执行一条建表语句看看有没有binlog存在服务器上面 确实有，在mysql里面看看日志，到这里mysql就配置好了！ 1.8 创建canal用户并授权mysql CREATE USER canal IDENTIFIED BY canal;mysql GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO canal@%;mysql FLUSH PRIVILEGES;mysql show grants for canal@%;+----------------------------------------------------------------------------+| Grants for canal@%% |+----------------------------------------------------------------------------+| GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `canal`@`%` |+----------------------------------------------------------------------------+1 row in set (0.00 sec) 1.9 创建example库create database woods_test； 二、搭建canal-server注意从这开始，就开始经历很多的坑，，，可能是对docker网络这部分不太熟的原因。 最开始的想法我最开始的想法是在一台服务器上的docker里面，运行一个mysql容器，运行一个canal-server容器，然后本地起一个java的canal客户端连接canal-server，监听数据库的增量binlog日志。思路看起来没啥问题。 开始探索以一条docker命令启动# bash run.sh -e canal.auto.scan=false -e canal.destinations=woods_test -e canal.instance.master.address=172.17.0.3:3306 -e canal.instance.dbUsername=canal -e canal.instance.dbPassword=canal -e canal.instance.connectionCharset=UTF-8 -e canal.instance.tsdb.enable=true -e canal.instance.gtidon=false 显示启动成功 Java客户端代码， 其实就是官网的demo public static void main(String args[]) // 创建链接 String hostIp = AddressUtils.getHostIp(); System.out.println(hostIp); CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress( 42.193.12.204, //canal-server的ip地址 11111), woods_test, canal, canal); int batchSize = 1000; int emptyCount = 0; try connector.connect(); connector.subscribe(.*\\\\..*); connector.rollback(); int totalEmptyCount = 120; while (emptyCount totalEmptyCount) Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) emptyCount++; System.out.println(empty count : + emptyCount); try Thread.sleep(1000); catch (InterruptedException e) else emptyCount = 0; // System.out.printf(message[batchId=%s,size=%s] , batchId, size); printEntry(message.getEntries()); connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 System.out.println(empty too many times, exit); finally connector.disconnect(); private static void printEntry(ListEntry entrys) for (Entry entry : entrys) if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) continue; RowChange rowChage = null; try rowChage = RowChange.parseFrom(entry.getStoreValue()); catch (Exception e) throw new RuntimeException(ERROR ## parser of eromanga-event has an error , data: + entry.toString(), e); EventType eventType = rowChage.getEventType(); System.out.println(String.format(================gt; binlog[%s:%s] , name[%s,%s] , eventType : %s, entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName(), eventType)); for (RowData rowData : rowChage.getRowDatasList()) if (eventType == EventType.DELETE) printColumn(rowData.getBeforeColumnsList()); else if (eventType == EventType.INSERT) printColumn(rowData.getAfterColumnsList()); else System.out.println(-------gt; before); printColumn(rowData.getBeforeColumnsList()); System.out.println(-------gt; after); printColumn(rowData.getAfterColumnsList()); private static void printColumn(ListColumn columns) for (Column column : columns) System.out.println(column.getName() + : + column.getValue() + update= + column.getUpdated()); 上面的Java客户端是怎么起都启动不起来，一直报这个错 Exception in thread main com.alibaba.otter.canal.protocol.exception.CanalClientException: failed to subscribe with reason: something goes wrong with channel:[id: 0x70fe412e, /118.112.75.194:7136 = /172.17.0.4:11111], exception=com.alibaba.otter.canal.server.exception.CanalServerException: destination:example should start first tail -fn 100 /home/admin/canal-server/logs/example/example.log //查日志 去docker容器里面查看日志找原因，发现是canal1.16版本的bug，使得canal-server会去查一张不存在的表，所以这里我修改了一下run.sh里面最后的cmd命令，指定了canal-server的版本 cmd=docker run -d -it -h $LOCALHOST $CONFIG --name=canal-server $VOLUMNS $NET_MODE $PORTS $MEMORY canal/canal-server:v1.1.4 再次启动java的canal-client，可以看到连接成功，正在定时获取binlog，如果监听的库有表的插入或更新，客户端就会打印出来 编写docker-compose.yml来启动version: 2services: canal-server: network_mode: bridge #因为我mysql是在这个默认的网络下面，所以我的canal-server也加入这个网络 image: canal/canal-server:v1.1.4 #最新的可能有bug，就用这个1.14吧 container_name: canal-server ports: - 11111:11111 environment: - canal.auto.scan=false - canal.destinations=woods_test - canal.instance.master.address=172.17.0.3:3306 #要监听的mysql地址 - canal.instance.dbUsername=canal - canal.instance.dbPassword=canal - canal.instance.connectionCharset=UTF-8 - canal.instance.tsdb.enable=true - canal.instance.gtidon=false - canal.instance.filter.regex=.*\\\\..* #监听规则 volumes: - ./canal-server/conf/:/admin/canal-server/conf/ #挂载文件至宿主机 - ./canal-server/logs/:/admin/canal-server/logs/ 启动java客户端后同样可以正确监听到woods_test数据库的变化。success！ 三、搭建canal-admin通过docker-compose 启动 canal-adminversion: 2services: canal-admin: network_mode: bridge #因为我mysql和canal-server是在这个默认的网络下面，所以我的canal-admin也加入这个网络 image: canal/canal-admin:v1.1.4 container_name: canal-admin ports: - 8089:8089 environment: - server.port=8089 - canal.adminUser=admin - canal.adminPasswd=admin 登录 ip:8089 canal-admin 管理界面 手动新建serverip就填canal-server的ip，端口就默认的那几个 手动新建instance改一下canal.instance.master.address就行，你的mysql IP地址 上面两步完成后，使用java的canal客户端进行连接，可以看到定时获取binlog的日志打印，如果监控的库有更新插入，则会有相应的日志打印出来，要注意的问题是，使用了admin客户端和server连接后，我们的java客户端在连接的时候不能使用之前用的明文的密码canal进行连接，需要使用密文 E3619321C1A937C46A0D8BD1DAC39F93B27D4458，或者你去mysql里查询 select password(canal); ## *E3619321C1A937C46A0D8BD1DAC39F93B27D4458 用不要星号的后面就行 ##java客户端连接 就变成这样了 // 创建链接 String hostIp = AddressUtils.getHostIp(); System.out.println(hostIp); CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress( 42.193.12.204, 11111), woods_test, canal, E3619321C1A937C46A0D8BD1DAC39F93B27D4458); int batchSize = 1000; int emptyCount = 0; 完结，撒花！","tags":["canal"],"categories":["canal"]},{"title":"常用分布式id分析，以及代码实战","path":"/2022/06/21/常用分布式id分析，以及代码实战/","content":"前言：分布式Id通常具备的特性 全局唯一：必须保证ID是全局性唯一的，基本要求 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求 一、UUID优点本地生成，没有网络的消耗 缺点 生成的字符串没有办法作为数据库的主键id，没有递增的趋势，查询性能差 生成的ID没有业务含义 二、数据库自增ID基于数据库的auto_increment自增ID完全可以充当分布式ID，具体实现：需要一个单独的MySQL实例用来生成ID，建表结构如下： CREATE DATABASE `SEQ_ID`;CREATE TABLE SEQID.SEQUENCE_ID ( id bigint(20) unsigned NOT NULL auto_increment, value char(10) NOT NULL default , PRIMARY KEY (id),) ENGINE=MyISAM;insert into SEQUENCE_ID(value) VALUES (values); 很多系统都用的数据库的自增主键作为表的主键，一般普通的业务量，这样其实也没有什么问题。 优点一定并发量内，实现简单，高效 缺点比如要作为订单id这种比较核心的主键id，被暴露在外网的时候容易被别人看出订单量，容易被爬虫爬数据，并发量达到一定程度，单表的MYSQL会成为系统的瓶颈。 四、号段模式号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下： CREATE TABLE id_generator ( id int(10) NOT NULL, max_id bigint(20) NOT NULL COMMENT 当前最大id, step int(20) NOT NULL COMMENT 号段的布长, biz_type int(20) NOT NULL COMMENT 业务类型, version int(20) NOT NULL COMMENT 版本号, PRIMARY KEY (`id`)) biz_type ：代表不同业务类型 max_id ：当前最大的可用id step ：代表号段的长度 version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性 等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。 update id_generator set max_id = #max_id+step, version = version + 1 where version = # version and biz_type = XXX 这种方式一定程度上减轻了数据库的访问，增加了并发量 五、RedisRedis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增 127.0.0.1:6379 set seq_id 1 // 初始化自增ID为1OK127.0.0.1:6379 incr seq_id // 增加1，并返回递增后的数值(integer) 2 这种方式的并发量基于redis的稳定性，如果要做高可用，那redis肯定要做一主多从，持久化（AOF或者RDB），不然redis宕机了会直接丢失自增的位置。 六、雪花算法（SnowFlake）雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法，开源后广受国内大厂的好评，在该算法影响下各大公司相继开发出各具特色的分布式生成器 雪花算法构成 四部分组成 1bit：符号位占用的位数，代表整个数字的正负，1代表负数，0代表正数，我们都用的正数，所以都是0，不改变它了 41bit：代表毫秒级别的时间戳占用的位数，(2^41)1000x60x60x24x365 69年多 1000：一秒等于1000毫秒 60：60分钟 60：60秒 24：24小时 365：365天 计算41毫秒的时间戳的时候，用的起始时间戳-代码运行时的时间戳，这个差值直接转换成我们的41bit位 10bit：机器位和数据中心心占用的位数 ，当然我们还可以把这10位拆分为我们几部分，以适应我们的业务需要，例如：机器位5位，数据中心5位，反正总共有2^101024台机器用这个雪花算法生成的id 12bit：序列号占用的位数，同一毫秒内，最大支持生成。2^12 4096, 即一毫秒可以有4096个id生成，并发量已经很高了，中小公司已经完全够了 Java实现代码(Mybatis-plus内雪花id生成实现)public class Sequence private static final Log logger = LogFactory.getLog(Sequence.class); /** * 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动） */ private final long twepoch = 1288834974657L; /** * 机器标识位数 */ private final long workerIdBits = 5L; //数据中心占用bit位 private final long datacenterIdBits = 5L; //机器标识位最大位 private final long maxWorkerId = -1L ^ (-1L workerIdBits); //数据中心标识位最大位 private final long maxDatacenterId = -1L ^ (-1L datacenterIdBits); /** * 毫秒内自增位 */ private final long sequenceBits = 12L; //机器标志位在自增位左边，所以机器标志位需要左移的位就是自增位 private final long workerIdShift = sequenceBits; //数据中心在机器标志位和自增位左边，所以数据中心位需要左移的位置就是自增位+机器标识位 private final long datacenterIdShift = sequenceBits + workerIdBits; /** * 时间戳左移动位 需要移动 自增位+机器标识位+数据中心位 */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private final long sequenceMask = -1L ^ (-1L sequenceBits); private final long workerId; /** * 数据标识 ID 部分 */ private final long datacenterId; /** * 并发控制 */ private long sequence = 0L; /** * 上次生产 ID 时间戳 */ private long lastTimestamp = -1L; public Sequence() this.datacenterId = getDatacenterId(maxDatacenterId); this.workerId = getMaxWorkerId(datacenterId, maxWorkerId); /** * 有参构造器 * * @param workerId 工作机器 ID * @param datacenterId 序列号 */ public Sequence(long workerId, long datacenterId) Assert.isFalse(workerId maxWorkerId || workerId 0, String.format(worker Id cant be greater than %d or less than 0, maxWorkerId)); Assert.isFalse(datacenterId maxDatacenterId || datacenterId 0, String.format(datacenter Id cant be greater than %d or less than 0, maxDatacenterId)); this.workerId = workerId; this.datacenterId = datacenterId; /** * 获取 maxWorkerId */ protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) StringBuilder mpid = new StringBuilder(); mpid.append(datacenterId); String name = ManagementFactory.getRuntimeMXBean().getName(); if (StringUtils.isNotBlank(name)) /* * GET jvmPid */ mpid.append(name.split(StringPool.AT)[0]); /* * MAC + PID 的 hashcode 获取16个低位 */ return (mpid.toString().hashCode() 0xffff) % (maxWorkerId + 1); /** * 数据标识id部分 */ protected static long getDatacenterId(long maxDatacenterId) long id = 0L; try InetAddress ip = InetAddress.getLocalHost(); NetworkInterface network = NetworkInterface.getByInetAddress(ip); if (network == null) id = 1L; else byte[] mac = network.getHardwareAddress(); if (null != mac) id = ((0x000000FF (long) mac[mac.length - 1]) | (0x0000FF00 (((long) mac[mac.length - 2]) 8))) 6; id = id % (maxDatacenterId + 1); catch (Exception e) logger.warn( getDatacenterId: + e.getMessage()); return id; /** * 获取下一个 ID * * @return 下一个 ID */ public synchronized long nextId() long timestamp = timeGen(); //处理闰秒 /** * 闰秒，是指为保持协调世界时接近于世界时时刻，由国际计量局统一规定在年底或年中（也可能在季末）对协调世界时增加或减少1秒 的调整。由于地球自转的不均匀性和长期变慢性（主要由潮汐摩擦引起的），会使世界时（民用时）和原子时之间相差超过到±0.9秒 时，就把协调世界时向前拨1秒（负闰秒，最后一分钟为59秒）或向后拨1秒（正闰秒，最后一分钟为61秒）； 闰秒一般加在公历年末 或公历六月末。 * 全球已经进行了27次闰秒，均为正闰秒。 * 最近一次闰秒在北京时间2017年1月1日7时59分59秒（时钟显示07:59:60）出现。这也是本世纪的第五次闰秒 */ if (timestamp lastTimestamp) long offset = lastTimestamp - timestamp; //如果上一次生成id的时间 - 现在的时间戳 = 5ms，说明时钟回拨了，时间回到了过去 if (offset = 5) try //等待offset的双倍时间后，再看当前时间是否大于上一次生成的时间 wait(offset 1); timestamp = timeGen(); if (timestamp lastTimestamp) throw new RuntimeException(String.format(Clock moved backwards. Refusing to generate id for %d milliseconds, offset)); catch (Exception e) throw new RuntimeException(e); else throw new RuntimeException(String.format(Clock moved backwards. Refusing to generate id for %d milliseconds, offset)); if (lastTimestamp == timestamp) // 相同毫秒内，序列号自增 sequence = (sequence + 1) sequenceMask; if (sequence == 0) // 同一毫秒的序列数已经达到最大 timestamp = tilNextMillis(lastTimestamp); else // 不同毫秒内，序列号置为 1 - 3 随机数 sequence = ThreadLocalRandom.current().nextLong(1, 3); lastTimestamp = timestamp; // 时间戳部分 | 数据中心部分 | 机器标识部分 | 序列号部分 return ((timestamp - twepoch) timestampLeftShift) | (datacenterId datacenterIdShift) | (workerId workerIdShift) | sequence; protected long tilNextMillis(long lastTimestamp) long timestamp = timeGen(); while (timestamp = lastTimestamp) timestamp = timeGen(); return timestamp; //高并发场景下System.currentTimeMillis()的性能问题的优化 protected long timeGen() return SystemClock.now(); 七、百度 （Uidgenerator）八、美团（Leaf）美团的Leaf有两种方案，一种号段模式，先获取数据库的一批Id，快用完的时候再去获取，供下批次使用 另一种是基于雪花算法的改进版本，引入了Zookeeper提高可用性。 Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。 九、滴滴出品（TinyID）Tinyid是用Java开发的一款分布式id生成系统，基于数据库号段算法实现，关于这个算法可以参考美团leaf或者tinyid原理介绍。Tinyid扩展了leaf-segment算法，支持了多db(master)，同时提供了java-client(sdk)使id生成本地化，获得了更好的性能与可用性。Tinyid在滴滴客服部门使用，均通过tinyid-client方式接入，每天生成亿级别的id 性能 http方式访问，性能取决于http server的能力，网络传输速度 java-client方式，id为本地生成，号段长度(step)越长，qps越大，如果将号段设置足够大，则qps可达1000w+ 可用性 依赖db，当db不可用时，因为server有缓存，所以还可以使用一段时间，如果配置了多个db，则只要有1个db存活，则服务可用 使用tiny-client，只要server有一台存活，则理论上可用，server全挂，因为client有缓存，也可以继续使用一段时间","tags":["分布式id"],"categories":["分布式id"]},{"title":"Configuration和Component用法和异同","path":"/2022/06/21/注解Configuration和注解Component用法和异同/","content":"一、各自在代码中的定义先看一下Spring中的类定义 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Configuration @AliasFor(annotation = Component.class) String value() default ; @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component String value() default ; 从代码定义上看@Configuration里面还是Component实现，所以该注解context:component-scan 或者 @ComponentScan 都能处理@Configuration的注解 二、用法@Configuration如单词意思一样，多用于java应用中一些配置类的声明，例如Redis的连接信息，mysql的连接信息，使用该注解声明配置信息，搭配@Bean注解使用，则@Bean注解标记的方法可以保证拿到的bean是单例的，比如mysql的连接信息，保证拿到的是spring容器中唯一的连接信息的bean实例，才能保证mysql事务的正确性。 @Datapublic class Person private String name;\tprivate Integer age;\tpublic Person() public Person(String name, Integer age) this.name = name; this.age = age;\t@Configurationpublic class MyConfiguration @Bean() public Person getPerson() return new Person(woods, 18); @Component就用的比较宽泛了，想要向spring容器中注入某种类型 bean实例，用该注解即可完成。但是如果该注解搭配@Bean注解使用，则@Bean注解标记的方法不能保证方法返回的bean实例是单例，调用多次返回的是不同的bean实例 @Componentpublic class MyComponent @Bean() public Person getPerson() return new Person(woods, 18); 三、返回同一个bean的原因造成不同结果的原因在ConfigurationClassPostProcessor类之中，通过调用enhanceConfigurationClasses方法，为被注解@Configuration的类进行CGLIB代理","tags":["Spring"],"categories":["Spring"]},{"title":"线程池的四种阻塞队列浅解","path":"/2022/06/21/线程池的四种阻塞队列浅解/","content":"一. ArrayBlockingQueue内部使用数组存储元素，利用reentrantlock实现线程安全，在创建的时候必须指定容量，之后也不可以再扩容了，在构造函数中可以指定是否公平，第一个参数是容量，第二个参数是是否公平。正如ReentrantLock一样，如果ArrayBlockingQueue被设置为非公平的，那么就存在插队的可能；如果设置为公平的，那么等待了最长时间的线程会被优先处理，其他线程不允许插队，不过这样的公平策略同时会带来一定的性能损耗，因为非公平的吞吐量通常会高于公平的情况。 public ArrayBlockingQueue(int capacity, boolean fair) if (capacity = 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); 二. LinkedBlockingQueue内部使用链表实现，可以指定容量，如果不指定，则为Integer.MAX_VALUE，就是说这个容量可以无限大，所以这个队列也被称为无界队列。基于链接节点的可选边界阻塞队列。该队列对元素进行 FIFO（先进先出，first in， first out）排序。队列的头部是队列中时间最长的元素。队列的尾部是在队列中时间最短的元素 public LinkedBlockingQueue(int capacity) if (capacity = 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new NodeE(null); 三.SynchronousQueue这个队列最大的不同就是，他不会存储元素，放元素和取元素的时候都会阻塞队列，比如我放一个数据到队列中，我是不能够立马返回的，我必须等待别人把我放进去的数据消费掉了，才能够返回 public SynchronousQueue(boolean fair) transferer = fair ? new TransferQueueE() : new TransferStackE(); 四.PriorityBlockingQueue前面我们所说的ArrayBlockingQueue和LinkedBlockingQueue都是采用先进先出的顺序进行排序，可是如果有的时候我们需要自定义排序怎么办呢？这时就需要使用PriorityBlockingQueue。 PriorityBlockingQueue是一个支持优先级的无界阻塞队列，可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。同时，插入队列的对象必须是可比较大小的，也就是Comparable的，否则会抛出ClassCastException异常。 //带比较类型的构造方法 public PriorityBlockingQueue(int initialCapacity, Comparator? super E comparator) if (initialCapacity 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity]; 五.DelayQueueDelayQueue这个队列比较特殊，具有“延迟”的功能。我们可以设定让队列中的任务延迟多久之后执行，比如10秒钟之后执行，这在例如“30分钟后未付款自动取消订单”等需要延迟执行的场景中被大量使用。它是无界队列，放入的元素必须实现Delayed接口，而Delayed接口又继承了Comparable接口，所以自然就拥有了比较和排序的能力，代码如下： import java.util.concurrent.DelayQueue;public class DelayQueueExample public static void main(String[] args) throws InterruptedException // 创建一个 DelayQueue DelayQueueDelayElement queue = new DelayQueue(); // 将三个延迟元素添加到队列中 queue.put(new DelayElement(1, 1000)); queue.put(new DelayElement(2, 2000)); queue.put(new DelayElement(3, 3000)); // 取出并输出队列中的元素 System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); class DelayElement implements Delayed private int data; private long delayTime; private long expire; public DelayElement(int data, long delayTime) this.data = data; this.delayTime = delayTime; this.expire = System.currentTimeMillis() + delayTime; // 实现 compareTo 方法 @Override public int compareTo(Delayed o) if (this.expire ((DelayElement)o).expire) return -1; else if (this.expire ((DelayElement)o).expire) return 1; else return 0; // 实现 getDelay 方法 @Override public long getDelay(TimeUnit unit) return unit.convert(this.expire - System.currentTimeMillis(), TimeUnit.MILLISECONDS); // 重写 toString 方法 @Override public String toString() return String.valueOf(this.data);","tags":["阻塞队列"],"categories":["异步编程"]},{"title":"SpringBoot笔记","path":"/2022/06/09/Spring笔记/","content":"一、核心思想1.IocIoC Inversion of Control (控制反转反转控制)，注意它是一个技术思想，不是一个技术实现 描述的事情:Java开发领域对象的创建，管理的问题 传统开发方式:比如类A依赖于类B，往往会在类A中new 一个B的对象 IoC思想下开发方式:我们不用自己去new对象了，而是由IoC容器(Spring框架)去帮助我们实例化对 象并且管理它，我们需要使用哪个对象，去问IoC容器要即可 我们丧失了一个权利(创建、管理对象的权利),得到了一个福利(不用考虑对象的创建、管理等一系列 事情) 为什么叫做控制反转? 控制:指的是对象创建(实例化、管理)的权利 反转:控制权交给外部环境了(spring框架、IoC容器) 解决了什么问题？ IoC解决了对象之间的耦合问题 2.Ioc和DI？DI：Dependancy Injection(依赖注入），这两个其实描述的是同一个事情，只不过角度不同罢了。 IOC是站在对象实例的角度，说的是把创建实例对象的权利交给Spring的容器了。 DI是站在容器的角度，说的是容器会把对象依赖的其他对象注入容器内。","tags":["SpringBoot"],"categories":["SpringBoot"]},{"title":"SpringBoot 中使用 Filter 的正确姿势","path":"/2022/03/16/SpringBoot 中使用 Filter 的正确姿势/","content":"SpringBoot 中使用 Filter 的正确姿势Filter 是 JavaEE 中 Servlet 规范的一个组件，位于包javax.servlet 中，它可以在 HTTP 请求到达 Servlet 之前，被一个或多个Filter处理。 它的工作流程如图： Filter的这个特性在生产环境中有很广泛的应用，如：修改请求和响应、防止xss攻击、包装二进制流使其可以多次读，等等。 实际工作中，我们都是使用 SpringBoot 进行业务开发，本文总结三种 Filter 用法，SpringBoot 版本采用目前最新的 v2.3.1.RELEASE 1. 编写Filter要编写 Filter ，只需要实现javax.servlet.Filter接口就可以了 public class MyFilter implements Filter @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException System.out.println(MyFilter); // 要继续处理请求，必须添加 filterChain.doFilter() filterChain.doFilter(servletRequest,servletResponse); Filter 接口有三个方法：init(),doFilter(),destroy()。 其中doFilter()需要自己实现，其余两个是default的，可以不用实现。 注意：如果Filter要使请求继续被处理，就一定要调用filterChain.doFilter()！ 2. 配置Filter被 Spring 管理让自定义的 Filter 被 Spring 的 IOC 容器管理，有三种实现方式，各有优缺点。下面课代表给大家总结一下： 1. 使用@Component+@Order在刚刚定义的MyFilter类上加上@Component和@Order注解，即可被Spring管理 @Component@Order(1)public class MyFilter implements Filter @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException System.out.println(MyFilter); // 要继续处理请求，必须添加 filterChain.doFilter() filterChain.doFilter(servletRequest,servletResponse); 没错就这么简单，这样 MyFilter 就生效了，写个Controller 调用一下就可以看到效果。 当有多个Filter时，这里的@Order(1)注解会指定执行顺序，数字越小，越优先执行，如果只写@Order，默认顺序值是Integer.MAX_VALUE。 @Component + @Order 注解方式配置简单，支持自定义 Filter 顺序。缺点是只能拦截所有URL，不能通过配置去拦截指定的 URL。 2.@WebFilter+@ServletComponentScan在 MyFilter上添加@WebFilter注解，并在启动类上增加@ServletComponentScan(com.zhengxl.filterdemo.filter)注解，参数就是Filter所在的包路径，相当于告诉 SpringBoot，去哪里扫描 Filter @WebFilter(urlPatterns = /*)public class MyFilter implements Filter @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException System.out.println(MyFilter); // 要继续处理请求，必须添加 filterChain.doFilter() filterChain.doFilter(servletRequest,servletResponse); @SpringBootApplication@ServletComponentScan(com.zhengxl.filterdemo.filter)public class FilterDemoApplication public static void main(String[] args) SpringApplication.run(FilterDemoApplication.class, args); @WebFilter+@ServletComponentScan 注解方式支持对 Filter 匹配指定URL，但是不支持指定 Filter 的执行顺序。 3. JavaConfig 配置方式@Configurationpublic class FilterConfig @Bean public FilterRegistrationBean registerMyFilter() FilterRegistrationBeanMyFilter bean = new FilterRegistrationBean(); bean.setOrder(1); bean.setFilter(new MyFilter()); // 匹配/hello/下面的所有url bean.addUrlPatterns(/hello/*); return bean; @Bean public FilterRegistrationBean registerMyAnotherFilter() FilterRegistrationBeanMyAnotherFilter bean = new FilterRegistrationBean(); bean.setOrder(2); bean.setFilter(new MyAnotherFilter()); // 匹配所有url bean.addUrlPatterns(/*); return bean; 通过 Java 代码显式配置 Filter ，功能强大，配置灵活。只需要把每个自定义的 Filter 声明成 Bean 交给 Spring 管理即可，还可以设置匹配的 URL 、指定 Filter 的先后顺序。 3. 三种方式对比以上介绍完 SpringBoot 中三种 Filter的使用姿势，非常简单，下面列个表格总结一下： 使用方式 排序 指定URL @Component @Order 1 0 @WebFilter @ServletComponentScan 0 1 JavaConfig 1 1 实际使用过程中，可以按照业务需求选择合适的使用方式，比如：如果编写的过滤器要拦截所有请求，不需要指定URL，那选择最简单的 @Component+@Order 就非常合适。","tags":["Spring Filter"],"categories":["Spring"]},{"title":"注册中心选型分析","path":"/2021/12/06/注册中心选型分析(未完成)/","content":"一. 认识注册中心注册中心的出现本来在后端的领域中是没有注册中心这个概念的，因为原来的单体应用架构，代码之间的各种调用都是在同一台服务器，所以不需要。 但是随着服务上云，分布式应用的兴起，就诞生了现在的微服务的架构模式，不同的业务服务放在不同的云服务器上面，所以就会有个非常显著的问题，不同的服务器之间的业务接口怎么相互调用，最简单的，直接用http实现相互的调用，这样子的确可以解决一定的问题。 http接口是在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段，优点就是简单、直接、开发方便。如果是一个大型的网站，内部子系统较多、接口非常多的情况下，RPC框架的好处就显示出来了：首先就是长链接，不必每次通信都要像http一样去3次握手什么的，减少了网络开销。 好了，现在解决了服务之间业务接口的调用问题，我们的微服务是不是就可以平稳的运行在我们的服务器上面了呢？答案是NO！你调的那个服务是不是有问题，是否是健康的，拿到的数据是否可用？如果宕机的服务恢复了状态，怎么通知其他服务“我”可以被调用了？如果某个服务挂了，是否整体业务雪崩？…… 自此，由于系统的复杂性不断提高以及容器部署方式的推行，服务消费者的调用信息无法简单地通过静态配置文件来保存，服务发现的工具—— 注册中心 由此诞生。 注册中心可以实现**「服务的注册」和「服务的发现」，服务的健康检查**，服务的注销，服务状态变跟的同步等等，总之，有了注册中心我们的微服务才能变得易用，高可用起来。 注册中心几个主要的功能 服务注册 作用：服务提供方将自身路由信息发布到注册中心，供消费方获取，用于与提供方建立连接并发起调用 需要提供给注册中心的内容： （1）路由信息：注册服务节点ip信息监听端口等路由信息 （2）服务信息：有序列化规则，路由规则，节点权重等 服务发现 作用：服务消费方通过访问注册中心获取服务提供方节点路由信息 获取服务提供方节点路由信息的时机： （1）启动拉取：服务消费方启动后，从注册中心拉取提供方节点列表，建立连接，进行RPC调用 （2）通知回调：接收注册中心变更通知，重新获取数据，更新节点列表 （3）轮询拉取：服务消费方运行过程中定时拉取服务提供方节点列表，用来更新本地数据 健康检查 作用：确保已注册节点的健康度，能够及时剔除失效节点，保证服务发现的正确性。 服务失效原因：服务重启、服务假死、异常终止 解决方案：上报心跳，服务探测 变更通知 当服务提供方节点发生变更的时候，注册中心应该能够第一时间将变更事件或者变更的数据通知给服务的订阅方 分布式和集群的区别集群: 多个服务器做同一个事情 分布式: 多个服务器做不同的事情 二. 现有注册中心概览 Feature Nacos Eureka Consul Zookeeper Etcd 一致性协议 CP+AP AP CP（ Raft） CP（ZAB） CP（Raft） 健康检查 TCPHTTPMYSQLClient Beat Client Beat TCPHTTPgrpcCmd KeepALive 连接心跳 负载均衡 权重metadataSelector Ribbon Fabio 不支持 支持 访问协议 HTTPDNS HTTP HTTPDNS TCP HTTP 监听支持 支持 支持 支持 不支持 支持 多数据中心 支持 不支持 支持 不支持 不支持 SpringCloud集成 支持 支持 支持 不支持 支持 K8s集成 支持 不支持 支持 不支持 支持 Nacos官方的压测结果，说的Nacos能够支持十万实例上下线。Eureka最多5000实例就已经出现服务不可用的问题，甚至在压测的过程中， 如果并发的线程数过高，就会造成 Eureka crash。 三. 专业名词介绍1.CAP协议1.1 一致性 (Consistency)所有节点访问时都是同一份最新的数据副本 1.2 可用性 (Availability)每次请求都能获取到非错的响应，但是不保证获取的数据为最新数据，换言之，系统中非故障节点收到的每个请求都必须有响应. 在可用系统中，如果我们的客户端向服务器发送请求，并且服务器未崩溃，则服务器必须最终响应客户端，不允许服务器忽略客户的请求 1.3 分区容错性 (Partition tolerance)分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致 性和可用性的服务，除非整个网络环境都发生了故障 CA关注一致性和可用性，它需要非常严格的全体一致的协议。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不 知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的的单机系统。 CP关注一致性和分区容忍性。它关注的是系统里大多数人 的一致性协议。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版 本的数据时变成不可用的状态。这样能够提供一部分的可用性。 AP这样的系统关心可用性和分区容忍性。因此，这样的系统 不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。 2.BASE理论上面我们讲到CAP 不可能同时满足，而分区容错性是对于分布式系统而言，是必须的。最后，我们说，如果系统能够同时实现 CAP 是再好不过的了，所以出现了 BASE 理论， BASE:全称:Basically Available(基本可用)，Soft state(软状态),和 Eventually consistent(最终一 致性)三个短语的缩写 ,Base 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的。其核心思想是: 即使无法做到强一致性，但是每个应用可以根据自身的业务特点，采用适当的方式达到最终一致性。 2.1 Basically Available(基本可用)什么是基本可用呢?假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言: 响应时间上的损失: 正常情况下的搜索引擎 0.5 秒即返回给用户结果，而基本可用的搜索引擎 可以在 1 秒返回结果。 功能上的损失: 在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单，但是到了大 促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面，比如数据加载失败，哎呦喂，被挤爆了，稍后重试。 2.2 Soft state(软状态)什么是软状态呢?相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种 “硬状态”。 软状态指的是: 允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 2.3 Eventually consistent(最终一致性)上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保 持数据一致性。从而达到数据的最终一致性。这个时间期限取决于网络延时，系统负载，数据复制方案设计等等因素。 3.分布式一致性协议通过上面的知识，我们可以感受到，一致性在分布式的架构中是非常重要的，所以各个分布式应用想要实现这种一致性的话，就必须有一个应用之间交互的协议，自然而然的各种分布式一致性协议就出现了。 3.1 两阶段提交协议(2PC)3.1.1 两阶段提交协议ACID A（atomicity）原子性 ：一个事务由多个小事件构成，要么都做，要么都不做 C（consistency）一致性 ：事务开始和事务结束后，数据库的完整性没有破坏，写入的资料必须符合所有预设约束 I（isolation）隔离性：事务与事务之间的执行是相互隔离的，不会影响彼此 D（durability）持久性 事务结束后，对数据库的修改是永久的，即使系统故障也没有 简称2PC(2 Prepare Commit)，是比较常用的解决分布式事务问题的方式，要么所有参与进程都提交事务，要么都取消事务，即实现ACID中的原子性(A)的常用手段。 3.1.2 2PC执行流程 成功提交事务流程 阶段一: 事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者 的响应。 执行事务 (写本地的UndoRedo日志) 各参与者向协调者反馈事务询问的响应 阶段二: 发送提交请求: 协调者向所有参与者发出 commit 请求。 事务提交: 参与者收到 commit 请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行期间占用的事务资源。 反馈事务提交结果: 参与者在完成事务提交之后，向协调者发送 Ack 信息。 完成事务: 协调者接收到所有参与者反馈的 Ack 信息后，完成事务。 中断的事务流程 假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参 与者的反馈响应，那么就会中断事务 阶段一: 事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者 的响应。 执行事务 (写本地的UndoRedo日志) 各参与者向协调者反馈事务询问的响应（图示一个不能执行，一个执行成功，一个超时未响应） 阶段二: 发送回滚请求: 协调者向所有参与者发出 Rollback 请求。 事务回滚: 参与者接收到 Rollback 请求后，会利用其在阶段一中记录的 Undo 信息来执行事务回滚操 作，并在完成回滚之后释放 整个事务执行期间占用的资源。 反馈事务回滚结果: 参与者在完成事务回滚之后，向协调者发送 Ack 信息。 中断事务: 协调者接收到所有参与者反馈的 Ack 信息后，完成事务中断。 优缺点 优点 理解简单，要么都做，要么都不做，保证原子性，即一致性。 缺点 同步阻塞在二阶段的提交过程中，所有参与该事务操作的逻辑都处于阻塞状态，既参与者占有公共资源时，其他节点访问公共资源会处于阻塞状态 单点问题若协调器出现问题，那么整个二阶段提交流程将无法运转，若协调者是在阶段二中出现问题 时，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作 数据不一致在阶段二中，执行事务提交的时候，当协调者向所有的参与者发送Commit请求之后，发生了 局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩溃，导致最终只有部 分参与者收到了Commit请求，于是会出现数据不一致的现象 3.2 三阶段提交协议四. 逐个介绍1. EurekaSpring-Cloud官方文档，搭配的注册中心就是用的eureka，属于Netflix公司的开源项目，但是2.0版本闭源了，停止更新和维护了，所以你如果要想能够不断更新和维护的注册中心的话，建议选择其他的注册中心。但是1.0的版本，对于中小型公司的体量，依然是足够了。 2. Nacos特性：注册中心、配置中心 2.1 SDK如何长监听nacos的server端的配置信息？SDK 通过 GRPC 长连接监听配置变更，Server 端对比 Client 端配置的 MD5 和本地 MD5是否相等，不相等推送配置变更。配置变更，服务端推送变更配置列表（注意这里只是返回需要更新的列表，这么做应该是减少无用的网络开销，需要更新的，重新发请求拉数据），然后 SDK 拉取配置更新，因此通信效率大幅提升 2.2 如果nacos的server端不可用，SDK如何可用？SDK 会保存配置的快照，当服务端出现问题的时候从本地获取。 Nacos 的客户端 SDK 会在本地生成配置的快照。当客户端无法连接到 Nacos Server 时，可以使 用配置快照显示系统的整体容灾能力。配置快照类似于 Git 中的本地 commit，也类似于缓存，会 在适当的时机更新，但是并没有缓存过期(expiration)的概念。 2.3 Nacos一致性协议Nacos 在开源支持就定下了一个目标，尽可能的减少用户部署以及运维成本，做到用户只需要一个 程序包，就可以快速以单机模式启动 Nacos 或者以集群模式启动 Nacos。而 Nacos 是一个需要 存储数据的一个组件，因此，为了实现这个目标，就需要在 Nacos 内部实现数据存储。单机下其 实问题不大，简单的内嵌关系型数据库即可;但是集群模式下，就需要考虑如何保障各个节点之间 的数据一致性以及数据同步，而要解决这个问题，就不得不引入共识算法，通过算法来保障各个节 点之间的数据的一致性。（ Raft 以及 Distro） 从服务发现注册来看，nacos强调服务发现注册中心的可用性，服务之间的感知全靠服务发现注册来获取相应的信息，因此要有很高的可用性，强一致性的共识算法这里就不太合适了，因为强一致 性共识算法能否对外提供服务是有要求的，如果当前集群可用的节点数没有过半的话，整个算法直 接“罢工”，而最终一致共识算法的话，更多保障服务的可用性，并且能够保证在一定的时间内各 个节点之间的数据能够达成一致。 从配置管理来看，配置必须准确，不能丢失，因此对于配置数据的管理，是必须要求集群中大部分的节点是强一致的，而这里的话只能使用强一致性共识算法。 2.4 Nacos的RaftRaft有很多成熟的工业算法实现，比如蚂蚁金服的 JRaft、Zookeeper 的 ZAB、Consul 的 Raft、 百度的 braft、Apache Ratis，因为 Nacos 是 Java 技术栈，因此只能在 JRaft、ZAB、Apache Ratis 中选择，但是 ZAB 因为和 Zookeeper 强绑定，再加上希望可以和 Raft 算法库的支持团队 随时沟通交流，因此选择了 JRaft，选择 JRaft 也是因为 JRaft 支持多 RaftGroup，为 Nacos后面的多数据分片带来了可能。 2.5 Nacos的Distro2.5.1 简介Distro 协议是阿里巴巴自研的一个最终一致性协议，而最终一致性协议有很多，比如 Gossip、 Eureka 内的数据同步算法。而 Distro 算法是集 Gossip 以及 Eureka 协议的优点并加以优化而出 来的，对于原生的 Gossip，由于随机选取发送消息的节点，也就不可避免的存在消息重复发送给同 一节点的情况，增加了网络的传输的压力，也给消息节点带来额外的处理负载，而 Distro 算法引入 了权威 Server 的概念，每个节点负责一部分数据以及将自己的数据同步给其他节点，有效的降低 了消息冗余的问题。 2.5.2 Distro 协议的主要设计思想如下Nacos 每个节点是平等的都可以处理写请求，同时把新数据同步到其他节点。（去中心化）每个节点只负责部分数据，定时发送自己负责数据的校验值到其他节点来保持数据一致性。每个节点独立处理读请求，及时从本地发出响应。 2.5.3 Distro的数据初始化新加入的 Distro 节点会进行全量数据拉取。具体操作是轮询所有的 Distro 节点，通过向其他的机器发送请求拉取全量数据。 2.5.4 Distro 集群数据校验这 种数据校验会以心跳的形式进行，即每台机器在固定时间间隔会向其他机器发起一次数据校验请求，一旦在数据校验过程中，某台机器发现其他机器上的数据与本地数据不一致，则会发起一次全量拉取请求，将数据补齐。 2.5.5 写操作1.前置的 Filter 拦截请求，并根据请求中包含的 IP 和 port 信息计算其所属的 Distro 责任节点， 2.并将该请求转发到所属的 Distro 责任节点上。责任节点上的 Controller 将写请求进行解析。3.Distro 协议定期执行 Sync 任务，将本机所负责的所有的实例信息同步到其他节点上。 2.5.6 读操作Distro是有本地缓存的，保证读操作的高可用 3. EtcdEtcd是Kubernetes用于存储集群各种状态信息（配置信息，运行）一个很重要的组件。 是兼具一致性和高可用性的键值对数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。在Kubernetes的世界里面，etcd是服务发现，集群状态存储以及其配置的基石。 如果微服务是通过K8s管理容器来部署微服务的话，etcd算是比较好的方案，因为etcd本身就属于K8s的组件，通过k8s service组件的方式提供服务的注册与发现，比 springboot 原生提供的 eureka、阿里的 nacos、zk 来作分布式的服务注册与发现要简单的多。减轻系统的繁重，以及避免了系统的冗余。 4.Consul在google上面看国外程序员对注册中心这一块，认可程度最高的好像就是这个Consul了，因为对这个Consul了解的不多，所以有点小惊讶，但是看受欢迎程度，这个组件被认可肯定是有原因的，但是国内用到的企业并不多，简单略过去。 具有最大弹性的单个 Consul 集群的推荐架构 优点缺点 同样的，集成 Consul 也变得比较麻烦，agent 的启动不是那么简单，特别是在 k8s 上我们需要多级 sidecar 时，同时其提供的 ACL 配置也难以理解和使用。相对于内部的实现，管控用的 GUI 界面也是大家吐槽比较多的地方。 相对于服务发现，其他 Consul 所提供的功能就显得不那么诱人了，比如 Key-Value 数据库以及多数据中心支持，当然我认为这也不是核心内容。 政治因素，其公司也参与了对中国企业的制裁，企业级软件无法使用，但是Consul是开源的，没问题。","tags":["eureka,zookeeper,nacos,etcd"],"categories":["注册中心"]},{"title":"docker安装minio，和其基本使用","path":"/2021/12/06/docker安装minio，和其基本使用/","content":"一.什么是分布式文件系统及拓展知识分布式文件系统（Distributed file system，DFS），或是网络文件系统（Network File System），是一种允许文件透过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。分布式文件系统解决的最大的问题是资源共享的问题，因此分布式文件系统最大的特点是多个客户端可以访问相同的服务端。 1.存储方式块存储、文件存储、对象存储 1.1 块存储就好比硬盘一样，直接挂在到主机， 一般用于主机的直接存储空间和数据库应用(MySQL)的存储 块存储(DASSAN)通常应用在某些专有的系统中，这类应用要求很高的随机读写性能和高可靠性，上面搭载的通常是 OracleDB2 这种传统数据库，连接通常是以 FC 光纤(8Gb16Gb)为主，走光纤协议。如果要求稍低一些，也会出现基于千兆万兆以太网的连接方式，MySQL 这种数据库就可能会使用 IP SAN，走 iSCSI 协议 通常使用块存储的都是系统而非用户，并发访问不会很多，经常出现一套存储只服务一个应用系统，例如如交易系统，计费系统。典型行业如金融，制造，能源，电信等 1.2 文件存储文件存储(NAS)相对来说就更能兼顾多个应用和更多用户访问，同时提供方便的数据共享手段 在 PC 时代，数据共享也大多是用文件的形式，比如常见的的 FTP 服务，NFS 服务，Samba 共享这些都是属于典型的文件存储。几十个用户甚至上百用户的文件存储共享访问都可以用 NAS 存储加以解决 在中小企业市场，一两台 NAS 存储设备就能支撑整个 IT 部门了。CRM 系统，SCM 系统，OA 系统，邮件系统都可以使用 NAS 存储统统搞定。甚至在公有云发展的早几年，用户规模没有上来时，云存储的底层硬件也有用几套 NAS 存储设备就解决的，甚至云主机的镜像也有放在 NAS 存储上的例子 文件存储的广泛兼容性和易用性，是这类存储的突出特点，但是从性能上来看，相对 SAN 就要低一些。NAS 存储基本上是以太网访问模式，普通千兆网，走 NFSCIFS 协议 1.3 对象存储前面说到的块存储和文件存储，基本上都还是在专有的局域网络内部使用，而对象存储的优势场景却是互联网或者公网，主要解决海量数据，海量并发访问的需求 基于互联网的应用才是对象存储的主要适配（当然这个条件同样适用于云计算，基于互联网的应用最容易迁移到云上），基本所有成熟的公有云都提供了对象存储产品，不管是国内还是国外 对象存储常见的适配应用如网盘、媒体娱乐，医疗 PACS，气象，归档等数据量超大而又相对 冷数据 和非在线处理的应用类型，这类应用单个数据大，总量也大，适合对象存储海量和易扩展的特点 网盘类应用也差不多，数据总量很大，另外还有并发访问量也大，支持 10 万级用户访问这种需求就值得单列一个项目了。归档类应用只是数据量大的 冷数据，并发访问的需求倒是不太突出 另外基于移动端的一些新兴应用也是适合的，智能手机和移动互联网普及的情况下，所谓 UGD（用户产生的数据，手机的照片视频）总量和用户数都是很大挑战。毕竟直接使用 HTTP getput 就能直接实现数据存取，对移动应用来说还是有一定吸引力的 对象存储的访问通常是在互联网，走 HTTP 协议，性能方面，单独看一个连接的是不高的（还要解决掉线断点续传之类的可靠性问题），主要强大的地方是支持的并发数量，聚合起来的性能带宽就非常可观了 1.4 性能对比 块存储就像超跑，根本不在意能不能多载几个人，要的就是极限速度和高速下的稳定性和可靠性，各大厂商出新产品都要去纽北赛道刷个单圈最快纪录，千方百计就为提高一两秒。块存储容量也不大，TB 这个数量级，支持的应用和适用的环境也比较专业（FC+Oracle），在乎的都是 IOPS 的性能值 文件存储像集卡，普适各种场合，又能装数据（数百TB），而且兼容性好，只要你是文件，各种货物都能往里塞，在不超过性能载荷的前提下，能拉动常见的各种系统。标准 POXIS 接口，后车门打开就能装卸。卡车也不挑路，不像块存储非要上赛道才能开，普通的千兆公路就能畅通无阻。速度虽然没有块存储超跑那么块，但跑个 80100 码还是稳稳当当 对象存储就像海运货轮，应对的是”真·海量”，几十上百 PB 的数据，以集装箱 container（桶bucket）为单位码得整整齐齐，里面装满各种对象数据，十万客户发的货（数据），一条船就都处理得过来，按照键值（KeyVaule）记得清清楚楚。海运速度慢是慢点，有时候遇到点网络风暴还不稳定，但支持断点续传，最终还是能安全送达的，对大宗货物尤其是非结构化数据，整体上来看是最快捷便利的 1.5 访问方式 块存储通常都是通过光纤网络连接，服务器小机上配置 FC 光纤 HBA 卡，通过光纤交换机连接存储（IP SAN 可以通过千兆以太网，以 iSCSI 客户端连接存储），主机端以逻辑卷（Volume）的方式访问。连接成功后，应用访问存储是按起始地址，偏移量 Offset 的方法来访问的 文件存储通常只要是局域网内，千兆百兆的以太网环境皆可。网线连上，服务器端通过操作系统内置的 NAS 客户端，如 NFSCIFSFTP 客户端挂载存储成为一个本地的文件夹后访问，只要符合 POXIS 标准，应用就可以用标准的 open，seek，writeread，close 这些方法对其访问操作 对象存储不在乎网络，而且它的访问比较有特色，只能存取删（putgetdelete），不能打开修改存盘。只能取下来改好后上传，去覆盖原对象 2. 文件系统开源分布式存储系统对比，还有很多其他，这里只列举这几款 存储系统 Ceph Swift HDFS FastDFS Ambry MinIO 开发语言 C++ Python Java C Java Go 开源协议 LGPL Apache Apache GPL3 Apache Apache 存储方式 对象文件块 对象 文件 文件块 对象 对象 在线扩容 支持 支持 支持 支持 支持 - 冗余备份 支持 支持 支持 支持 支持 - 单点故障 不存在 不存在 存在 不存在 不存在 - 易用性 一般 一般 一般 简单 简单 简单 跨集群 不支持 - 不支持 部分支持 不支持 - 适用场景 大中小文件 大中小文件 大中文件 中小文件 大中小文件 大中小文件 对比了 Github 的 Star，MinIO 增长的很快，而且官方还有中文文档提供，中小企业使用不错 二. docker安装Minio2.1 拉取Minio docker镜像docker pull minio //这里我是拉取的最新的镜像 2.2 运行镜像docker run -p 9000:9000 -p 9090:9090 --name minio \\ -d --restart=always \\ -e MINIO_ACCESS_KEY=minio \\ -e MINIO_SECRET_KEY=minio@123 \\ -v /usr/local/minio/data:/data \\ -v /usr/local/minio/config:/root/.minio \\ minio/minio server /data --console-address :9000 --address :9090 9000是minio控制台端口 9090是api交互端口 三. JavaSDK使用3.1 上传文件minioClient = MinioClient.builder().endpoint(Url).credentials(AccessKey,SecretKey).build(); // Make asiatrip bucket if not exist. boolean found = minioClient.bucketExists(BucketExistsArgs.builder().bucket(Bucket).build()); if (!found) // Make a new bucket called asiatrip. //minioClient.makeBucket(MakeBucketArgs.builder().bucket(asiatrip).build()); System.out.println(不存在!!!); else System.out.println(Bucket already exists.); // Upload /home/user/Photos/asiaphotos.zip as object name asiaphotos-2015.zip to bucket // asiatrip. minioClient.uploadObject( UploadObjectArgs.builder() .bucket(Bucket) .object(笔记.zip) .filename(/Users/woods/candaoCodes/woodsTest/src/main/resources/笔记.zip) .build()); 3.2 下载文件minioClient = MinioClient.builder().endpoint(Url).credentials(AccessKey,SecretKey).build(); String presignedObjectUrl = minioClient.getPresignedObjectUrl( GetPresignedObjectUrlArgs.builder() .method(Method.GET) .bucket(Bucket) .object(笔记.zip) .expiry(10000) .build()); System.out.println(presignedObjectUrl); //下载链接","tags":["minio"],"categories":["分布式文件系统"]},{"title":"SpringBoot自动配置浅析","path":"/2021/10/31/SpringBoot自动配置浅析/","content":"一、应用的入口是SpringBoot启动类启动类位置在项目的根目录，为什么要在根目录？启动类的main方法启动的时候，项目主程序启动类要定义在最外层的根目录位 置，然后在根目录位置内部建立子包和类进行业务开发，这样才能够保证定义的类能够被组件扫描器扫描 可被扫描的组件有哪些？@Component，@Controller，@Service，@Repository，等等具体作用就不介绍了，用过spring的兄弟都懂。 二、@SpringBootApplication包含的三个重要注解1. @SpringBootConfiguration表明该类为配置类，底层还是spring的@configuration注解，标识一个可以被组件扫描器扫描的配置类 2.@EableAutoConfiguration简述：借助@Import注解的支持，收集和注册特定场景的bean 该注解下又分为以下两个重要的注解 （1）@AutoConfigurationPackage@AutoConfigurationPackage注解的主要作用就是将主程序类所在包及所有子包下的组件到扫描到spring容器中。 （2）@Import(AutoConfigurationImportSelector.class)@Import是Spring提供的注解，目的就是将所有符合自动配置条件的bean定义加载到IoC容器 AutoConfigurationImportSelector类作用 是通过selectImports方法执行的过程中，会使用内部工具类SpringFactoriesLoader，查找 classpath上所有jar包中的META-INFspring.factories进行加载，实现将配置类信息交给 SpringFactory加载器进行一系列的容器创建过程 3.@ComponentScan这个注解是spring提供的，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。 注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。 三、底层实现自动配置的步骤 Springboot应用启动; @SpringBootApplication起作用; @EnableAutoConfiguration; @AutoConfigurationPackage:这个组合注解主要是 @Import(AutoConfigurationPackages.Registrar.class)，它通过将Registrar类导入到容器中，而 Registrar类作用是扫描主配置类同级目录以及子包，并将相应的组件导入到springboot创建管理 的容器中; @Import(AutoConfigurationImportSelector.class):它通过将 AutoConfigurationImportSelector类导入到容器中，AutoConfigurationImportSelector类作用 是通过selectImports方法执行的过程中，会使用内部工具类SpringFactoriesLoader，查找 classpath上所有jar包中的META-INFspring.factories进行加载，实现将配置类信息交给 SpringFactory加载器进行一系列的容器创建过程 四、整体启动流程1.获取并启动监听器this.getRunListeners(args)和listeners.starting()方法主要用于获取SpringApplication实例初始化过程中初始化的SpringApplicationRunListener监听器并运行。 2.根据SpringApplicationRunListeners以及参数来准备环境this.prepareEnvironment(listeners, applicationArguments)方法主要用于对项目运行环境进 行预设置，同时通过this.configureIgnoreBeanInfo(environment)方法排除一些不需要的运行环境 3.创建Spring容器根据webApplicationType进行判断， 确定容器类型，如果该类型为SERVLET类型，会通过反射装载 对应的字节码，也就是AnnotationConfigServletWebServerApplicationContext，接着使用之前 初始化设置的context(应用上下文环境)、environment(项目运行环境)、listeners(运行监听 器)、applicationArguments(项目参数)和printedBanner(项目图标信息)进行应用上下文的组 装配置，并刷新配置 4.Spring容器前置处理这一步主要是在容器刷新之前的准备动作。设置容器环境，包括各种变量等等，其中包含一个非常关键的操作:将启动类注入容器，为后续开启自动化配置奠定基础 5.刷新容器开启刷新spring容器，通过refresh方法对整个IOC容器的初始化(包括bean资源的定位，解析，注册等 等)，同时向JVM运行时注册一个关机钩子，在JVM关机时会关闭这个上下文，除非当时它已经关闭 6.Spring容器后置处理扩展接口，设计模式中的模板方法，默认为空实现。如果有自定义需求，可以重写该方法。比如打印一些启 动结束log，或者一些其它后置处理。 7.发出结束执行的事件获取EventPublishingRunListener监听器，并执行其started方法，并且将创建的Spring容器传进去 了，创建一个ApplicationStartedEvent事件，并执行ConfigurableApplicationContext 的 publishEvent方法，也就是说这里是在Spring容器中发布事件，并不是在SpringApplication中发布 事件，和前面的starting是不同的，前面的starting是直接向SpringApplication中的监听器发布启 动事件。 8.执行Runners用于调用项目中自定义的执行器XxxRunner类，使得在项目启动完成后立即执行一些特定程序。其中， Spring Boot提供的执行器接口有ApplicationRunner 和CommandLineRunner两种，在使用时只需要自定义一个执行器类实现其中一个接口并重写对应的run()方法接口，然后Spring Boot项目启动后会立即执行这些特定程序","tags":["SpringBoot"],"categories":["SpringBoot"]},{"title":"什么是递归算法？","path":"/2021/10/31/什么是递归算法？/","content":"首先明确什么是递归算法? 递归算法是把问题转化为规模缩小了的同类问题的子问题，然后递归调用函数（或过程）来表示问题的解。一个过程(或函数)直接或间接调用自己本身，这种过程(或函数)叫递归过程(或函数)。 递归过程一般通过函数或子过程来实现。递归方法：在函数或子过程的内部，直接或者间接地调用自己的算法。递归其实就是在栈内存中不断的加载同一个函数 什么时候用递归呢?当一个功能被重复使用，而每一次使用该功能时的参数不确定，都由上次的功能元素结果来确定。 递归的注意事项 必须有可最终达到的终止条件，否则程序将陷入无穷循环出现栈内存溢出错误（StackOverflowError）； 递归的次数不能太多； 子问题在规模上比原问题小，或更接近终止条件； 子问题可通过再次递归调用求解或因满足终止条件而直接求解； 子问题的解应能组合为整个问题的解。 递归的三要素 明确递归终止条件； 给出递归终止时的处理办法； 提取重复的逻辑，缩小问题规模问题可被分解成多个小的问题，问题的演化是由大到小的。","tags":["递归的定义"],"categories":["排序算法"]}]